import random
import re
from datetime import datetime
import spacy
from textblob import TextBlob
from collections import Counter
from twilio.rest import Client

# Load Spacy's small English model for Named Entity Recognition
nlp = spacy.load('en_core_web_sm')

# Twilio API credentials (replace with your actual credentials)
account_sid = 'ACe2eac9b1ccb7556df7ee92ba2d0658d7'
auth_token = '06b1210263feda5bb4cad4d11c0c9352'
twilio_whatsapp_number = 'whatsapp:+17625839557'

# Function to fetch WhatsApp messages from Twilio API
def get_whatsapp_messages(account_sid, auth_token):
    client = Client(account_sid, auth_token)
    messages = client.messages.list(limit=100)  # Fetch up to 100 messages
    chat_data = []

    for message in messages:
        # Filter messages to exclude automated replies and messages from the Twilio number
        if message.from_ and 'whatsapp' in message.from_ and 'whatsapp:+14155238886' not in message.from_:
            chat_data.append({
                "timestamp": message.date_sent.strftime('%Y-%m-%dT%H:%M:%SZ'),
                "sender": message.from_,
                "message": message.body
            })

    return chat_data

# Function to count occurrences of keywords in a sentence
def keyword_match(sentence, keywords):
    words = sentence.lower().split()
    keyword_count = {}

    for word in words:
        if word in keywords:
            if word in keyword_count:
                keyword_count[word] += 1
            else:
                keyword_count[word] = 1

    return keyword_count

# List of keywords related to drug usage
keywords = [
    "drugs", "alcohol", "nicotine", "marijuana", "cocaine", "heroin", "methamphetamine", "prescription",
    "opioids", "benzodiazepines", "mdma", "lsd", "valium", "xanax", "kilos", "weed", "blow", "crack", "dope",
    "ecstasy", "molly", "speed", "smack", "ice", "pot", "acid", "maal", "phukenge", "snow", "foggy"
]

# Function to determine alert level based on the count of keyword matches
def get_alert_level(count):
    if count < 2:
        return "\033[92m"  # Green (Low Alert)
    elif count < 4:
        return "\033[93m"  # Yellow (Medium Alert)
    else:
        return "\033[91m"  # Red (High Alert)

# Function for NLP analysis including sentiment analysis and named entity recognition
def analyze_nlp(text):
    if text.strip():  # Ensure text is not empty or whitespace
        blob = TextBlob(text)
        sentiment = blob.sentiment.polarity  # Sentiment score (-1 to 1)

        doc = nlp(text)
        entities = [(ent.text, ent.label_) for ent in doc.ents]  # Extract named entities

        return sentiment, entities
    return 0, []  # Return neutral sentiment and no entities for empty messages

# Function to analyze conversations with metadata and NLP features
def analyze_conversations(metadata_list, person):
    keyword_count = Counter()
    print(f"\nAnalyzing conversations of {person}:")

    # Skip the last 5 conversations
    messages_to_analyze = metadata_list[:-5]

    for metadata in messages_to_analyze:
        timestamp = metadata['timestamp']
        sender = metadata['sender']
        message = metadata['message']

        # Analyze messages from specified senders
        if sender in ['whatsapp:+918109576579', 'whatsapp:+14155238886']:
            sentiment, entities = analyze_nlp(message)

            # Skip messages with a sentiment score of 0.00 or specific phrases
            if sentiment != 0.00 and "join circus-ahead" not in message.lower() and "stop" not in message.lower():
                print(f"\033[94mTime: {timestamp}\033[0m")  # Blue color for time
                print(f"\033[94mSender: {sender}\033[0m")  # Blue color for sender
                print(f"Message: {message}")
                print(f"\033[94mSentiment Score: {sentiment:.2f}\033[0m")  # Blue color for sentiment score
                print(f"Entities: {entities}")
                print("-" * 50)

                # Perform keyword matching
                keyword_result = keyword_match(message, keywords)
                keyword_count.update(keyword_result)

    # Print keyword match counts with alert levels
    print(f"Suspected keyword matches: {len(keyword_count)}")
    for keyword, count in keyword_count.items():
        alert_level = get_alert_level(count)
        print(f"{alert_level}{keyword.capitalize()} : {count} times\033[0m")

# Fetch WhatsApp messages from Twilio
chat_data = get_whatsapp_messages(account_sid, auth_token)

# If messages are fetched, analyze them
if chat_data:
    analyze_conversations(chat_data, "Jamie and Alex")
else:
    print("No messages found.")

# Function to generate random IP addresses
def generate_random_ip():
    return '.'.join(str(random.randint(0, 255)) for _ in range(4))

# Generate random metadata for demonstration purposes
p1 = generate_random_ip()
p2 = generate_random_ip()

print("\nIP ADDRESS OF PERSON 1: ", p1)
print("IP ADDRESS OF PERSON 2: ", p2)
print("PHONE NUMBER OF PERSON 1: +918109576579")
print("PHONE NUMBER OF PERSON 2: +14155238886")
